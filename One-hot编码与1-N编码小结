                                                          One-hot编码与1-N编码小结
一、进行特征编码原因
    数据中可能会带有各种非数值型特征，而实际上机器学习模型需要的数据是数值型的，只有数值型才能进行运算。因此，对于各种特殊的特征值，我们都需要对其进行相应的编码，也是量化的过程。

二、特征编码类型
1.独热编码One-hot encoding
    pandas.get_dummies(特征列);独热编码就是将原始特征变量转换成以原始特征值分类的多维度的变量，并用是否（0,1）这种方式的新特征值替代和量化。
2.标签编码Label encoding
    Label encoding就是将原始特征值编码为自定义的数字标签完成量化编码过程。

三、两种编码方式的优缺点
1.One-hot encoding
1）优点
    解决了分类器不好处理分类数据的问题，在一定程度上也起到了扩充特征的作用。它的值只有0和1，不同的类型存储在垂直的空间。
2）缺点
    当类别的数量很多时，特征空间会变得非常大，容易造成维度灾难。
2.Label encoding
1）优点
    解决了分类编码的问题，可以自由定义量化数字。但其实也是缺点，因为数值本身没有任何含义，只是排序。如大中小编码为123，也可以编码为321，即数值没有意义。
2）缺点
    可解释性比较差。

四、两种编码的使用场景
1.对于定类类型的数据，建议使用one-hot encoding。
    定类类型就是纯分类，不排序，没有逻辑关系。比如性别分男和女，男女不存在任何逻辑关系，我们不能说男就比女好，或者相反。这时候使用one-hot encoding会合适些。但注意，一般会舍去一个变量，比如男的对立面肯定是女，那么女就是重复信息，所以保留其中一个变量即可。
2.对于定序类型的数据，建议使用label encoding。
    定序类型也是分类，但有排序逻辑关系，等级上高于定类。比如，学历分小学，初中，高中，本科，研究生，各个类别之间存在一定的逻辑，显然研究生学历是最高的，小学最低。这时候使用Label encoding会显得更合适，因为自定义的数字顺序可以不破坏原有逻辑，并与这个逻辑相对应。
3.对数值大小敏感的模型必须使用one-hot encoding。
    典型的例子就是LR和SVM。二者的损失函数对数值大小是敏感的。
    但树模型不建议使用one-hot encoding。如果分类类别特别多，那么one-hot encoding会分裂出很多特征变量。如果限制了树模型的深度而不能向下分裂的话，一些特征变量可能就因为模型无法继续分裂而被舍弃损失掉了。
